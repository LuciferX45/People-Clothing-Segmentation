{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXYeTh-gXNCF"
      },
      "source": [
        "# **People Clothing Segmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqw1kZOZXNCH"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N5j_WBsyXNCH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsJ7znnpXNCJ",
        "outputId": "7cd427b3-8cb6-4041-bb61-c458bb962ace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.11).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rajkumarl/people-clothing-segmentation?dataset_version_number=2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616M/616M [00:29<00:00, 21.8MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files:  /root/.cache/kagglehub/datasets/rajkumarl/people-clothing-segmentation/versions/2\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download('rajkumarl/people-clothing-segmentation')\n",
        "print(\"Path to dataset files: \", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G4_HxYXiXNCJ"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Bgq53qXNCJ",
        "outputId": "2affd011-ce97-410c-abea-614a9dae1eb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['png_images',\n",
              " 'png_masks',\n",
              " 'jpeg_images',\n",
              " 'jpeg_masks',\n",
              " 'labels (1).csv',\n",
              " 'labels.csv']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jNGVmD4UXNCJ"
      },
      "outputs": [],
      "source": [
        "# Set up paths and constants\n",
        "DATASET_PATH = path  # Update with your path\n",
        "IMAGE_DIR = os.path.join(DATASET_PATH, 'png_images/IMAGES')\n",
        "MASK_DIR = os.path.join(DATASET_PATH, 'png_masks/MASKS')\n",
        "CLASSES_FILE = os.path.join(DATASET_PATH, 'labels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w63aQHbaXNCJ",
        "outputId": "a5ded4cc-7551-4c91-eb74-e24f4854eb19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image Directory:  /root/.cache/kagglehub/datasets/rajkumarl/people-clothing-segmentation/versions/2/png_images/IMAGES\n",
            "Mask Directory:  /root/.cache/kagglehub/datasets/rajkumarl/people-clothing-segmentation/versions/2/png_masks/MASKS\n",
            "Classes File:  /root/.cache/kagglehub/datasets/rajkumarl/people-clothing-segmentation/versions/2/labels.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"Image Directory: \", IMAGE_DIR)\n",
        "print(\"Mask Directory: \", MASK_DIR)\n",
        "print(\"Classes File: \", CLASSES_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YhwKUZppXNCJ"
      },
      "outputs": [],
      "source": [
        "IMAGE_HEIGHT = 544\n",
        "IMAGE_WIDTH = 824\n",
        "NUM_CLASSES = 60  # 59 clothing classes + background\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "VALIDATION_SPLIT = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AD8JqE9XNCK"
      },
      "source": [
        "## 2. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "j7iTvk3YXNCK"
      },
      "outputs": [],
      "source": [
        "def read_image(image_path):\n",
        "    \"\"\"Read and preprocess an image.\"\"\"\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0,1]\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OBDzng09XNCK"
      },
      "outputs": [],
      "source": [
        "def resize_data(image, mask, height=IMAGE_HEIGHT, width=IMAGE_WIDTH):\n",
        "    \"\"\"Resize image and mask to the specified dimensions.\"\"\"\n",
        "    image = tf.image.resize(image, [height, width])\n",
        "    mask = tf.image.resize(mask, [height, width], method='nearest')\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nONHRjPLXNCK"
      },
      "outputs": [],
      "source": [
        "def augment_data(image, mask):\n",
        "    \"\"\"Apply data augmentation to image and mask.\"\"\"\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        mask = tf.image.flip_left_right(mask)\n",
        "\n",
        "    # Random brightness adjustment (only for image, not mask)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "    # Ensure image values stay in [0, 1]\n",
        "    image = tf.clip_by_value(image, 0, 1)\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4Wfo7759XNCK"
      },
      "outputs": [],
      "source": [
        "def read_mask(mask_path):\n",
        "    \"\"\"Read and preprocess a segmentation mask.\"\"\"\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    # No need to normalize masks as they contain class indices\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Fo1UYcf8XNCK"
      },
      "outputs": [],
      "source": [
        "def prepare_sample(image_path, mask_path):\n",
        "    \"\"\"Prepare a single sample (image and mask).\"\"\"\n",
        "    image = read_image(image_path)\n",
        "    mask = read_mask(mask_path)\n",
        "\n",
        "    # Resize to target dimensions\n",
        "    image, mask = resize_data(image, mask)\n",
        "\n",
        "    # Apply augmentation during training\n",
        "    image, mask = augment_data(image, mask)\n",
        "\n",
        "    # Convert mask to one-hot encoding\n",
        "    mask = tf.squeeze(mask)  # Remove the channel dimension\n",
        "    mask = tf.one_hot(tf.cast(mask, tf.int32), NUM_CLASSES)\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "IyXsWjI-XNCK"
      },
      "outputs": [],
      "source": [
        "def create_dataset(image_paths, mask_paths):\n",
        "    \"\"\"Create a TensorFlow dataset from image and mask paths.\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
        "    dataset = dataset.map(prepare_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XM77KU_hXNCK"
      },
      "outputs": [],
      "source": [
        "# Create a function to read and process the image and mask\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load images and masks from the dataset and split into training/validation sets.\n",
        "    Returns: train_dataset, val_dataset, class_names\n",
        "    \"\"\"\n",
        "    # Read class names\n",
        "    class_df = pd.read_csv(CLASSES_FILE)\n",
        "    class_names = ['background'] + class_df['label_list'].tolist()\n",
        "\n",
        "    # Get all image filenames\n",
        "    image_files = sorted([os.path.join(IMAGE_DIR, fname) for fname in os.listdir(IMAGE_DIR)\n",
        "                          if fname.endswith('.png')])\n",
        "    mask_files = sorted([os.path.join(MASK_DIR, fname) for fname in os.listdir(MASK_DIR)\n",
        "                         if fname.endswith('.png')])\n",
        "\n",
        "    # Ensure we have matching number of images and masks\n",
        "    assert len(image_files) == len(mask_files), \"Number of images and masks don't match!\"\n",
        "    print(f\"Found {len(image_files)} images and masks\")\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    train_img_files, val_img_files, train_mask_files, val_mask_files = train_test_split(\n",
        "        image_files, mask_files, test_size=VALIDATION_SPLIT, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(train_img_files)} images\")\n",
        "    print(f\"Validation set: {len(val_img_files)} images\")\n",
        "\n",
        "    # Create TensorFlow datasets\n",
        "    train_dataset = create_dataset(train_img_files, train_mask_files)\n",
        "    val_dataset = create_dataset(val_img_files, val_mask_files)\n",
        "\n",
        "    return train_dataset, val_dataset, class_names\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJZuVrLtXNCL"
      },
      "source": [
        "## 3. Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kOUfnJvJXNCL"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    \"\"\"\n",
        "    Build a simpler U-Net model for semantic segmentation.\n",
        "    This implementation avoids dimension matching issues.\n",
        "    Returns: Compiled model\n",
        "    \"\"\"\n",
        "    # Define input layer\n",
        "    inputs = layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "\n",
        "    # Contracting path (encoder)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    # Bridge\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    c4 = layers.Dropout(0.2)(c4)  # Add dropout for regularization\n",
        "\n",
        "    # Expansive path (decoder)\n",
        "    u5 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c4)\n",
        "    u5 = layers.concatenate([u5, c3])\n",
        "    c5 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u5)\n",
        "    c5 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    u6 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c2])\n",
        "    c6 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c1])\n",
        "    c7 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(NUM_CLASSES, (1, 1), activation='softmax')(c7)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgmvP5T0XNCL"
      },
      "source": [
        "## 4. Visualization Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wLops0nmXNCL"
      },
      "outputs": [],
      "source": [
        "# Custom callback to display segmentation results during training\n",
        "class SegmentationDisplayCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, dataset, num_samples=2):\n",
        "        self.dataset = dataset\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % 2 == 0:  # Display every 2 epochs\n",
        "            samples = self.dataset.take(self.num_samples)\n",
        "            plt.figure(figsize=(15, 5 * self.num_samples))\n",
        "\n",
        "            for i, (image, mask) in enumerate(samples):\n",
        "                # Show original image\n",
        "                plt.subplot(self.num_samples, 3, i*3 + 1)\n",
        "                plt.imshow(image[0])\n",
        "                plt.title(f\"Image\")\n",
        "                plt.axis('off')\n",
        "\n",
        "                # Show ground truth mask (only show the argmax class for visualization)\n",
        "                plt.subplot(self.num_samples, 3, i*3 + 2)\n",
        "                plt.imshow(tf.argmax(mask[0], axis=-1), cmap='nipy_spectral')\n",
        "                plt.title(f\"True Mask\")\n",
        "                plt.axis('off')\n",
        "\n",
        "                # Show predicted mask\n",
        "                pred_mask = self.model.predict(image)\n",
        "                plt.subplot(self.num_samples, 3, i*3 + 3)\n",
        "                plt.imshow(tf.argmax(pred_mask[0], axis=-1), cmap='nipy_spectral')\n",
        "                plt.title(f\"Predicted Mask\")\n",
        "                plt.axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"segmentation_epoch_{epoch}.png\")\n",
        "            plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-0ys3BVXNCL"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8lEMiUpYXNCL"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_model(model, train_data, val_data):\n",
        "    \"\"\"\n",
        "    Train the model on the training set and validate on the validation set.\n",
        "    \"\"\"\n",
        "    # Set up callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            \"best_model.h5\", save_best_only=True, monitor=\"val_mean_io_u\"\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6\n",
        "        ),\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
        "        ),\n",
        "        SegmentationDisplayCallback(val_data)\n",
        "    ]\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_data,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_data,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['mean_io_u'], label='Training IoU')\n",
        "    plt.plot(history.history['val_mean_io_u'], label='Validation IoU')\n",
        "    plt.title('Training and Validation IoU')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('IoU')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_history.png\")\n",
        "    plt.show()\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1x-qcAGXNCL"
      },
      "source": [
        "## 6. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nLpMoyXPXNCL"
      },
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(model, val_data, class_names):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the validation set and display metrics.\n",
        "    \"\"\"\n",
        "    print(\"Evaluating model on validation set...\")\n",
        "    results = model.evaluate(val_data)\n",
        "\n",
        "    print(f\"Loss: {results[0]:.4f}\")\n",
        "    print(f\"Accuracy: {results[1]:.4f}\")\n",
        "    print(f\"Mean IoU: {results[2]:.4f}\")\n",
        "\n",
        "    # Visualize some predictions\n",
        "    samples = val_data.take(5)\n",
        "    plt.figure(figsize=(15, 20))\n",
        "\n",
        "    for i, (image, mask) in enumerate(samples):\n",
        "        # Predict masks\n",
        "        pred_mask = model.predict(image)\n",
        "\n",
        "        for j in range(min(2, len(image))):  # Show up to 2 images from each batch\n",
        "            # Show original image\n",
        "            plt.subplot(5, 3, i*3 + j*3 + 1)\n",
        "            plt.imshow(image[j])\n",
        "            plt.title(f\"Image\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Show ground truth mask\n",
        "            plt.subplot(5, 3, i*3 + j*3 + 2)\n",
        "            true_mask = tf.argmax(mask[j], axis=-1)\n",
        "            plt.imshow(true_mask, cmap='nipy_spectral')\n",
        "            plt.title(f\"True Mask\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Show predicted mask\n",
        "            plt.subplot(5, 3, i*3 + j*3 + 3)\n",
        "            predicted_mask = tf.argmax(pred_mask[j], axis=-1)\n",
        "            plt.imshow(predicted_mask, cmap='nipy_spectral')\n",
        "            plt.title(f\"Predicted Mask\")\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"validation_results.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate class-wise IoU\n",
        "    iou_per_class = []\n",
        "    # Implement class-wise IoU calculation here\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RpUSOE7XNCL"
      },
      "source": [
        "## 7. Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yL-UOyv1XNCL",
        "outputId": "f24c7f8b-314e-47fc-afd5-097825ea751c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "Loading and preparing dataset...\n",
            "Found 1000 images and masks\n",
            "Training set: 800 images\n",
            "Validation set: 200 images\n",
            "Building model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,900</span> │ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m544\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m544\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m1,792\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m544\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m136\u001b[0m, \u001b[38;5;34m206\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m136\u001b[0m, \u001b[38;5;34m206\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m136\u001b[0m, \u001b[38;5;34m206\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │      \u001b[38;5;34m2,359,808\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m136\u001b[0m, \u001b[38;5;34m206\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m524,544\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m136\u001b[0m, \u001b[38;5;34m206\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m136\u001b[0m, \u001b[38;5;34m206\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │      \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m136\u001b[0m, \u001b[38;5;34m206\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m590,080\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m131,200\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m295,040\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m272\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m544\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m544\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m544\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m544\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m544\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m60\u001b[0m)   │          \u001b[38;5;34m3,900\u001b[0m │ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,701,180</span> (29.38 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,701,180\u001b[0m (29.38 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,701,180</span> (29.38 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,701,180\u001b[0m (29.38 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "Epoch 1/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7336 - loss: 1.4964 - mean_io_u: 0.4958"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 2s/step - accuracy: 0.7337 - loss: 1.4952 - mean_io_u: 0.4958 - val_accuracy: 0.7700 - val_loss: 1.0963 - val_mean_io_u: 0.5196 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 2s/step - accuracy: 0.7688 - loss: 1.0699 - mean_io_u: 0.5219 - val_accuracy: 0.7694 - val_loss: 1.0283 - val_mean_io_u: 0.5228 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7685 - loss: 1.1250 - mean_io_u: 0.5289"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 734ms/step\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 2s/step - accuracy: 0.7685 - loss: 1.1253 - mean_io_u: 0.5289 - val_accuracy: 0.7700 - val_loss: 1.0781 - val_mean_io_u: 0.5108 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.7714 - loss: 1.0358 - mean_io_u: 0.5304 - val_accuracy: 0.7722 - val_loss: 1.0039 - val_mean_io_u: 0.5323 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7726 - loss: 0.9991 - mean_io_u: 0.5432"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828ms/step\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 1s/step - accuracy: 0.7725 - loss: 0.9991 - mean_io_u: 0.5432 - val_accuracy: 0.7749 - val_loss: 0.9887 - val_mean_io_u: 0.4998 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 2s/step - accuracy: 0.7730 - loss: 0.9806 - mean_io_u: 0.5365 - val_accuracy: 0.7751 - val_loss: 0.9697 - val_mean_io_u: 0.5048 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776ms/step\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - accuracy: 0.7759 - loss: 0.9571 - mean_io_u: 0.5352 - val_accuracy: 0.7773 - val_loss: 0.9492 - val_mean_io_u: 0.5243 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 1s/step - accuracy: 0.7766 - loss: 0.9457 - mean_io_u: 0.5395 - val_accuracy: 0.7820 - val_loss: 0.9124 - val_mean_io_u: 0.5158 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m 71/200\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 1s/step - accuracy: 0.7839 - loss: 0.8987 - mean_io_u: 0.5289"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Load data\n",
        "print(\"Loading and preparing dataset...\")\n",
        "train_data, val_data, class_names = load_data()\n",
        "\n",
        "# Build model\n",
        "print(\"Building model...\")\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "# Train model\n",
        "print(\"Training model...\")\n",
        "history = train_model(model, train_data, val_data)\n",
        "\n",
        "# Evaluate model\n",
        "print(\"Evaluating model...\")\n",
        "results = evaluate_model(model, val_data, class_names)\n",
        "\n",
        "# Save the model\n",
        "model.save('segmentation_model.h5')\n",
        "print(\"Model saved as 'segmentation_model.h5'\")\n",
        "\n",
        "# Export model to TF SavedModel format\n",
        "tf.saved_model.save(model, 'saved_model')\n",
        "print(\"Model exported as SavedModel format in 'saved_model' directory\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pcs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
